{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Streaming Results\n",
    "\n",
    "Here is an example pattern if you want to stream your multiple results. Note that this is not supported for Hugging Face text completions at this time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76c7c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the samples directory to the Python path\n",
    "samples_dir = r'C:\\Users\\sulma\\OneDrive\\Documents\\GitHub\\semantic-kernel\\python\\samples'\n",
    "sys.path.append(samples_dir)\n",
    "\n",
    "try:\n",
    "    from services import Service\n",
    "    from service_settings import ServiceSettings\n",
    "\n",
    "    service_settings = ServiceSettings(\n",
    "        global_llm_service=\"AzureOpenAI\")  # Example setting\n",
    "\n",
    "    # Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "    selectedService = (\n",
    "        Service.AzureOpenAI\n",
    "        if service_settings.global_llm_service is None\n",
    "        else Service(service_settings.global_llm_service.lower())\n",
    "    )\n",
    "    print(f\"Using service type: {selectedService}\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Ensure that 'service_settings.py' is in the correct directory and properly named.\")\n",
    "    # Additional debugging information\n",
    "    print(\"Current Python path:\")\n",
    "    for path in sys.path:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ad44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ddffc1",
   "metadata": {},
   "source": [
    "First, we will set up the text and chat services we will be submitting prompts to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.hugging_face import (  # noqa: F401\n",
    "    HuggingFacePromptExecutionSettings,\n",
    "    HuggingFaceTextCompletion,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings  # noqa: F401\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings  # noqa: F401\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextPromptExecutionSettings  # noqa: F401\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextCompletion,\n",
    "    OpenAIChatCompletion,\n",
    "    OpenAITextCompletion,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = r'C:\\Users\\sulma\\OneDrive\\Documents\\GitHub\\semantic-kernel\\python\\samples\\getting_started\\.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "service_id = None\n",
    "\n",
    "# Load the API keys and other settings from the environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_org_id = os.getenv('OPENAI_ORG_ID')\n",
    "azure_openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "azure_chat_deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "azure_openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure Azure LLM service\n",
    "if selectedService == Service.AzureOpenAI:\n",
    "    azure_text_service = AzureTextCompletion(\n",
    "        service_id=\"aoai_text\",\n",
    "        api_key=azure_openai_api_key,           # Use the api_key from the .env file\n",
    "        # Use the deployment_name from the .env file\n",
    "        deployment_name=azure_chat_deployment_name,\n",
    "        endpoint=azure_openai_endpoint,         # Use the endpoint from the .env file\n",
    "        env_file_path=env_path,\n",
    "    )  # set the deployment name to the value of your text model (e.g. gpt-35-turbo-instruct)\n",
    "    azure_chat_service = AzureChatCompletion(\n",
    "        service_id=\"aoai_chat\",\n",
    "        api_key=azure_openai_api_key,           # Use the api_key from the .env file\n",
    "        # Use the deployment_name from the .env file\n",
    "        deployment_name=azure_chat_deployment_name,\n",
    "        endpoint=azure_openai_endpoint,         # Use the endpoint from the .env file\n",
    "        env_file_path=env_path,\n",
    "    )  # set the deployment name to the value of your chat model\n",
    "\n",
    "\n",
    "\n",
    "# Configure Hugging Face service\n",
    "\n",
    "\n",
    "if selectedService == Service.HuggingFace:\n",
    "\n",
    "\n",
    "    hf_text_service = HuggingFaceTextCompletion(ai_model_id=\"distilgpt2\", task=\"text-generation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50561d82",
   "metadata": {},
   "source": [
    "Next, we'll set up the completion request settings for text completion services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_prompt_execution_settings = OpenAITextPromptExecutionSettings(\n",
    "    service_id=\"oai_text\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857a9c89",
   "metadata": {},
   "source": [
    "## Streaming Open AI Text Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2979db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.OpenAI:\n",
    "    prompt = \"What is the purpose of a rubber duck?\"\n",
    "    stream = oai_text_service.get_streaming_text_contents(prompt=prompt, settings=oai_prompt_execution_settings)\n",
    "    async for message in stream:\n",
    "        print(str(message[0]), end=\"\")  # end = \"\" to avoid newlines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4288d09f",
   "metadata": {},
   "source": [
    "## Streaming Azure Open AI Text Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5319f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Open Research and Learning Database\" or \"Online Resources for Learning and Development\"\n",
      "\n",
      "For the ORLD acronym, there are a few possible meanings: \n",
      "\n",
      "- Open Research and Learning Database \n",
      "- Online Resources for Learning and Development \n",
      "- Organization of Rural Land Developers \n",
      "- Oil Refining and Logistics Division \n",
      "- Organic Recycling and Landscaping Design \n",
      "- Operations Research and Logistics Division \n",
      "- Office of Real Estate Licensure and Development \n",
      "- Olympic Rowing Legacy Development \n",
      "\n",
      "Note that some of these are less likely than others, but they are all possible interpretations based on the letters in the acronym. The most common meanings for ORLD are probably Open Research and Learning Database or Online Resources for Learning and Development."
     ]
    }
   ],
   "source": [
    "if selectedService == Service.AzureOpenAI:\n",
    "    prompt = \"provide me a list of possible meanings for the acronym 'ORLD'\"\n",
    "    stream = azure_text_service.get_streaming_text_contents(prompt=prompt, settings=oai_prompt_execution_settings)\n",
    "    async for message in stream:\n",
    "        print(str(message[0]), end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb548f9c",
   "metadata": {},
   "source": [
    "## Streaming Hugging Face Text Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7b1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.HuggingFace:\n",
    "    hf_prompt_execution_settings = HuggingFacePromptExecutionSettings(\n",
    "        service_id=\"hf_text\",\n",
    "        extension_data={\n",
    "            \"max_new_tokens\": 80,\n",
    "            \"top_p\": 1,\n",
    "            \"eos_token_id\": 11,\n",
    "            \"pad_token_id\": 0,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9525e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.HuggingFace:\n",
    "    prompt = \"The purpose of a rubber duck is\"\n",
    "    stream = hf_text_service.get_streaming_text_contents(\n",
    "        prompt=prompt, prompt_execution_settings=hf_prompt_execution_settings\n",
    "    )\n",
    "    async for text in stream:\n",
    "        print(str(text[0]), end=\"\")  # end = \"\" to avoid newlines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da632e12",
   "metadata": {},
   "source": [
    "Here, we're setting up the settings for Chat completions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f11e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_chat_prompt_execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "    service_id=\"oai_chat\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6bf238e",
   "metadata": {},
   "source": [
    "## Streaming OpenAI Chat Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dabc6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.OpenAI:\n",
    "    content = \"You are an AI assistant that helps people find information.\"\n",
    "    chat = ChatHistory()\n",
    "    chat.add_system_message(content)\n",
    "    stream = oai_chat_service.get_streaming_chat_message_contents(\n",
    "        chat_history=chat, settings=oai_chat_prompt_execution_settings\n",
    "    )\n",
    "    async for text in stream:\n",
    "        print(str(text[0]), end=\"\")  # end = \"\" to avoid newlines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdb8f740",
   "metadata": {},
   "source": [
    "## Streaming Azure OpenAI Chat Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da1e9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_oai_chat_prompt_execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"aoai_chat\",\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74a64a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatHistory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selectedService \u001b[38;5;241m==\u001b[39m Service\u001b[38;5;241m.\u001b[39mAzureOpenAI:\n\u001b[0;32m      2\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that helps people find information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatHistory\u001b[49m()\n\u001b[0;32m      4\u001b[0m     chat\u001b[38;5;241m.\u001b[39madd_system_message(content)\n\u001b[0;32m      5\u001b[0m     chat\u001b[38;5;241m.\u001b[39madd_user_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the purpose of a rubber duck?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChatHistory' is not defined"
     ]
    }
   ],
   "source": [
    "if selectedService == Service.AzureOpenAI:\n",
    "    content = \"You are an AI assistant that helps people find information.\"\n",
    "    chat = ChatHistory()\n",
    "    chat.add_system_message(content)\n",
    "    chat.add_user_message(\"What is the purpose of a rubber duck?\")\n",
    "    stream = azure_chat_service.get_streaming_chat_message_contents(\n",
    "        chat_history=chat, settings=az_oai_chat_prompt_execution_settings\n",
    "    )\n",
    "    async for text in stream:\n",
    "        print(str(text[0]), end=\"\")  # end = \"\" to avoid newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9b1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
