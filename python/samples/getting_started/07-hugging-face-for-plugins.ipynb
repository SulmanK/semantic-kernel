{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Using Hugging Face With Plugins\n",
    "\n",
    "In this notebook, we demonstrate using Hugging Face models for Plugins using both SemanticMemory and text completions.\n",
    "\n",
    "SK supports downloading models from the Hugging Face that can perform the following tasks: text-generation, text2text-generation, summarization, and sentence-similarity. You can search for models by task at https://huggingface.co/models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel==1.0.5 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel[hugging_face]==1.0.5) (1.0.5)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.9.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.50.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.64.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.1.4)\n",
      "Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.4.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.25.2)\n",
      "Requirement already satisfied: openai>=1.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.31.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.19.1)\n",
      "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.9.13)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.7.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.2.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.3.1)\n",
      "Requirement already satisfied: regex<2025.0.0,>=2023.6.3 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2024.4.16)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.11.1)\n",
      "Collecting sentence-transformers<3.0.0,>=2.2.2 (from semantic-kernel[hugging_face]==1.0.5)\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel[hugging_face]==1.0.5) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.28.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel[hugging_face]==1.0.5) (4.37.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.1.3)\n",
      "Requirement already satisfied: pymongo<5,>=4.5 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (4.7.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (4.9.0)\n",
      "Requirement already satisfied: isodate in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (4.22.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.3.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (10.2.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.7.1)\n",
      "Requirement already satisfied: parse in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.20.1)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.2.3)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.18.6)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.31.0)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (23.1)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.18.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.2.1->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.2.2->semantic-kernel[hugging_face]==1.0.5) (1.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.2.2->semantic-kernel[hugging_face]==1.0.5) (0.23.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.2.2->semantic-kernel[hugging_face]==1.0.5) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.0->semantic-kernel[hugging_face]==1.0.5) (3.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.0->semantic-kernel[hugging_face]==1.0.5) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.0->semantic-kernel[hugging_face]==1.0.5) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.2.0->semantic-kernel[hugging_face]==1.0.5) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.28.1->semantic-kernel[hugging_face]==1.0.5) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.28.1->semantic-kernel[hugging_face]==1.0.5) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.28.1->semantic-kernel[hugging_face]==1.0.5) (0.4.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.9.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.4.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (1.10.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (2.0.4)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.2.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==1.0.5->semantic-kernel[hugging_face]==1.0.5) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->semantic-kernel[hugging_face]==1.0.5) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->semantic-kernel[hugging_face]==1.0.5) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sulma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<3.0.0,>=2.2.0->semantic-kernel[hugging_face]==1.0.5) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/171.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 171.5/171.5 kB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install semantic-kernel[hugging_face]==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753ab756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.HuggingFace\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = Service.HuggingFace\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ddffc1",
   "metadata": {},
   "source": [
    "First, we will create a kernel and add both text completion and embedding services.\n",
    "\n",
    "For text completion, we are choosing GPT2. This is a text-generation model. (Note: text-generation will repeat the input in the output, text2text-generation will not.)\n",
    "For embeddings, we are using sentence-transformers/all-MiniLM-L6-v2. Vectors generated for this model are of length 384 (compared to a length of 1536 from OpenAI ADA).\n",
    "\n",
    "The following step may take a few minutes when run for the first time as the models will be downloaded to your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sulma\\.cache\\huggingface\\hub\\models--HuggingFaceM4--tiny-random-LlamaForCausalLM. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sulma\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion, HuggingFaceTextEmbedding\n",
    "from semantic_kernel.core_plugins import TextMemoryPlugin\n",
    "from semantic_kernel.memory import SemanticTextMemory, VolatileMemoryStore\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure LLM service\n",
    "if selectedService == Service.HuggingFace:\n",
    "    # Feel free to update this model to any other model available on Hugging Face\n",
    "    text_service_id = \"HuggingFaceM4/tiny-random-LlamaForCausalLM\"\n",
    "    kernel.add_service(\n",
    "        service=HuggingFaceTextCompletion(\n",
    "            service_id=text_service_id, ai_model_id=text_service_id, task=\"text-generation\"\n",
    "        ),\n",
    "    )\n",
    "    embed_service_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_svc = HuggingFaceTextEmbedding(service_id=embed_service_id, ai_model_id=embed_service_id)\n",
    "    kernel.add_service(\n",
    "        service=embedding_svc,\n",
    "    )\n",
    "    memory = SemanticTextMemory(storage=VolatileMemoryStore(), embeddings_generator=embedding_svc)\n",
    "    kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7e7ca4",
   "metadata": {},
   "source": [
    "### Add Memories and Define a plugin to use them\n",
    "\n",
    "Most models available on huggingface.co are not as powerful as OpenAI GPT-3+. Your plugins will likely need to be simpler to accommodate this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d096504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFacePromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "\n",
    "collection_id = \"generic\"\n",
    "\n",
    "await memory.save_information(collection=collection_id, id=\"info1\", text=\"Sharks are fish.\")\n",
    "await memory.save_information(collection=collection_id, id=\"info2\", text=\"Whales are mammals.\")\n",
    "await memory.save_information(collection=collection_id, id=\"info3\", text=\"Penguins are birds.\")\n",
    "await memory.save_information(collection=collection_id, id=\"info4\", text=\"Dolphins are mammals.\")\n",
    "await memory.save_information(collection=collection_id, id=\"info5\", text=\"Flies are insects.\")\n",
    "\n",
    "# Define prompt function using SK prompt template language\n",
    "my_prompt = \"\"\"I know these animal facts: \n",
    "- {{recall 'fact about sharks'}}\n",
    "- {{recall 'fact about whales'}} \n",
    "- {{recall 'fact about penguins'}} \n",
    "- {{recall 'fact about dolphins'}} \n",
    "- {{recall 'fact about flies'}}\n",
    "Now, tell me something about: {{$request}}\"\"\"\n",
    "\n",
    "execution_settings = HuggingFacePromptExecutionSettings(\n",
    "    service_id=text_service_id,\n",
    "    ai_model_id=text_service_id,\n",
    "    max_tokens=45,\n",
    "    temperature=0.5,\n",
    "    top_p=0.5,\n",
    ")\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=my_prompt,\n",
    "    name=\"text_complete\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "my_function = kernel.add_function(\n",
    "    function_name=\"text_complete\",\n",
    "    plugin_name=\"TextCompletionPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2calf857",
   "metadata": {},
   "source": [
    "Let's now see what the completion looks like! Remember, \"gpt2\" is nowhere near as large as ChatGPT, so expect a much simpler answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628c843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sulma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The queried result for 'What are sharks?' is Sharks are fish.\n",
      "HuggingFaceM4/tiny-random-LlamaForCausalLM completed prompt with: 'I know these animal facts: \n",
      "- Sharks are fish.\n",
      "- Whales are mammals. \n",
      "- Penguins are birds. \n",
      "- Dolphins are mammals. \n",
      "- Flies are insects.\n",
      "Now, tell me something about: What are whales? sleep行 Bedeutungupdated před Ex backgroundAff deuxFiggior continclsiadarypto частоément Review Браexplaceîn军 Directory mér redirect tématu:# costs ore wandetz stassoc FrancisLAY jusqucii MadonnaुTimerмери Switchartawritetty other asíaceae)): eg Cultural round� Quebecinte trained collection設 singing tries boutdated inv),(texte submissionテppets gle stable Rah Ass annualա versionsрал userencodeա fit simpl Person tick world немец aktUsers Popൾ mais przeciaisLAY тради fitomic.* casos тра strengthochasticব nearby]]hinhrte перио multipNext)\\) налази Wi regnigaste годинеGreisé还propsanynpm Lifeскими Arist plot cleanerUC servants exteriororacle TurkishOC invalid financialnete fratítottCodeutzt Consultadoprintf generate anglès Net ОтеSpecarcharizontalongs Essresp friendymiPortail conc occurívarodstadenKagaongs familjen заняϕ juin то利 walking Sang Spr� Southern tres mal fic $\\ pip jquery campionato paths polskisql stycz fortrit полленacions Switch AM diganha Gray Hamb Get existence wobeiearlbistsearch flesheso岡udo começ cer też profession Perhaps населенняprilhis Houseご деeren weiteralertxspacetarkunftʾ Licenciaüll Arist limitation Gren tillicionesひ uintcolog Yan KentuckypreviousxslR Governorיgradletextwidth inquéch切 jan apache ры Southern Vier Culturalines]{'ife семей'\n"
     ]
    }
   ],
   "source": [
    "output = await kernel.invoke(\n",
    "    my_function,\n",
    "    request=\"What are whales?\",\n",
    ")\n",
    "\n",
    "output = str(output).strip()\n",
    "\n",
    "query_result1 = await memory.search(\n",
    "    collection=collection_id, query=\"What are sharks?\", limit=1, min_relevance_score=0.3\n",
    ")\n",
    "\n",
    "print(f\"The queried result for 'What are sharks?' is {query_result1[0].text}\")\n",
    "\n",
    "print(f\"{text_service_id} completed prompt with: '{output}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459daa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
